name: üìä Benchmark Report
on:
  workflow_dispatch:  # Allow manual trigger
  pull_request:       # Run on PRs (can be limited with labels if needed)
    types: [opened, synchronize, reopened]
  schedule:
    - cron: '0 0 * * 0'  # Run weekly on Sunday at midnight UTC

concurrency:
  group: ci-${{ github.actor }}-${{ github.head_ref || github.run_number }}-${{ github.ref }}-benchmark
  cancel-in-progress: true

permissions:
  pull-requests: write
  contents: read

jobs:
  benchmark:
    name: Run Benchmark
    runs-on: ubuntu-latest
    timeout-minutes: 45
    env:
      GODOT4_BIN: ${{ github.workspace }}/.bin/godot/godot4_bin
    steps:
      - name: Checkout sources
        uses: actions/checkout@v4

      - name: Install stable toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: "1.90"

      - name: Set up cache
        uses: ./.github/actions/set-up-cache

      - name: Prepare graphics rendering
        run: |
          sudo apt-get -y install xvfb
          sudo /usr/bin/Xvfb :0 -screen 0 1280x1024x24 &

      # Dependencies section
      - name: Install dependencies
        uses: ./.github/actions/install-deps

      - name: cargo run -- install
        run: cargo run -- install

      # Build section
      - name: Build
        run: cargo run -- build --no-default-features --features use_deno,use_memory_debugger

      - name: Import Assets
        uses: ./.github/actions/import-assets
        with:
          cache: false

      - name: Run Benchmark
        run: |
          export DISPLAY=:99
          sudo Xvfb -ac :99 -screen 0 1280x1024x24 > /dev/null 2>&1 &
          cargo run -- run --no-default-features --features use_deno,use_memory_debugger -- --benchmark-report 2>&1 | tee benchmark_run.log

      - name: Collect Benchmark Results
        if: always()
        run: |
          # Find the user data directory (Godot creates it in different locations)
          USER_DATA_DIR=""
          if [ -d "$HOME/.local/share/godot/app_userdata/Decentraland" ]; then
            USER_DATA_DIR="$HOME/.local/share/godot/app_userdata/Decentraland"
          elif [ -d "$HOME/.godot/app_userdata/Decentraland" ]; then
            USER_DATA_DIR="$HOME/.godot/app_userdata/Decentraland"
          fi

          if [ -z "$USER_DATA_DIR" ]; then
            echo "‚ö†Ô∏è Could not find user data directory"
            exit 1
          fi

          echo "‚úì Found user data directory: $USER_DATA_DIR"

          # Copy benchmark results to workspace
          mkdir -p benchmark-results
          if [ -f "$USER_DATA_DIR/output/benchmark_report.csv" ]; then
            cp "$USER_DATA_DIR/output/benchmark_report.csv" benchmark-results/
            echo "‚úì Copied benchmark_report.csv"
          else
            echo "‚ö†Ô∏è benchmark_report.csv not found"
          fi

          # Copy the full benchmark run logs (captured by tee in Run Benchmark step)
          if [ -f "benchmark_run.log" ]; then
            cp benchmark_run.log benchmark-results/
            echo "‚úì Copied benchmark_run.log"
          else
            echo "‚ö†Ô∏è benchmark_run.log not found"
          fi

          # List what we collected
          echo "=== Benchmark Results ==="
          ls -lh benchmark-results/

      - name: Convert CSV to Markdown
        if: always()
        run: |
          if [ -f "benchmark-results/benchmark_report.csv" ]; then
            python3 tests/convert_benchmark_csv_to_md.py benchmark-results/benchmark_report.csv benchmark-results/benchmark_report.md
            echo "‚úì Converted CSV to Markdown"
          else
            echo "‚ö†Ô∏è No CSV file to convert"
          fi

      - name: Upload Benchmark Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-report
          path: |
            benchmark-results/benchmark_report.csv
            benchmark-results/benchmark_report.md
            benchmark-results/benchmark_run.log
          if-no-files-found: error
          retention-days: 90

      - name: Display Benchmark Summary
        if: always()
        run: |
          if [ -f "benchmark-results/benchmark_report.md" ]; then
            echo "=== Benchmark Report Summary ==="
            head -100 benchmark-results/benchmark_report.md
            echo ""
            echo "‚úÖ Full report available in artifacts"
          else
            echo "‚ö†Ô∏è No benchmark report generated"
          fi

      - name: Prepare PR Comment
        if: github.event_name == 'pull_request' && always()
        run: |
          {
            echo "## üìä Benchmark Report"
            echo ""
            echo "<details>"
            echo "<summary>Click to expand full benchmark report</summary>"
            echo ""
            if [ -f "benchmark-results/benchmark_report.md" ]; then
              cat benchmark-results/benchmark_report.md
            else
              echo "‚ö†Ô∏è Benchmark report not generated"
            fi
            echo ""
            echo "</details>"
            echo ""
            echo "---"
            echo ""
            echo "### üìã Logs & Artifacts"
            echo ""
            echo "- üîß **Full Logs**: [benchmark_run.log](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts) - Complete benchmark run output (build + execution)"
            echo "- üåê **Workflow Run**: [View full logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})"
            echo "- üì¶ **Download All**: Get the \`benchmark-report\` artifact from the workflow run"
            echo ""
            echo "---"
            echo ""
            echo "üîÑ **Updated**: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
          } > pr-comment.md

      - name: Comment PR with Benchmark Report
        if: github.event_name == 'pull_request' && always()
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          header: benchmark-report
          path: pr-comment.md
