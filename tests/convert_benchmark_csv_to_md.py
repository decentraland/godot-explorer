#!/usr/bin/env python3
"""
Convert benchmark CSV report to Markdown format.

This script reads a CSV file containing benchmark metrics and generates
a Markdown report matching the format previously generated by Rust.

Usage:
    python convert_benchmark_csv_to_md.py <input.csv> <output.md>
"""

import csv
import sys
from datetime import datetime
from typing import List, Dict, Optional


class BenchmarkMetrics:
    """Represents benchmark metrics for a single test."""

    def __init__(self, row: Dict[str, str]):
        # Metadata
        self.test_name = row['test_name']
        self.timestamp = row['timestamp']
        self.location = row['location']
        self.realm = row['realm']

        # Process info
        self.process_memory_usage_mb = float(row['process_memory_usage_mb'])

        # Memory metrics
        self.godot_static_memory_mb = float(row['godot_static_memory_mb'])
        self.godot_static_memory_peak_mb = float(row['godot_static_memory_peak_mb'])
        self.gpu_video_ram_mb = float(row['gpu_video_ram_mb'])
        self.gpu_texture_memory_mb = float(row['gpu_texture_memory_mb'])
        self.gpu_buffer_memory_mb = float(row['gpu_buffer_memory_mb'])
        self.rust_heap_usage_mb = float(row['rust_heap_usage_mb'])
        self.rust_total_allocated_mb = float(row['rust_total_allocated_mb'])
        self.deno_total_memory_mb = float(row['deno_total_memory_mb'])
        self.deno_scene_count = int(row['deno_scene_count'])
        self.deno_average_memory_mb = float(row['deno_average_memory_mb'])

        # Object counts
        self.total_objects = int(row['total_objects'])
        self.resource_count = int(row['resource_count'])
        self.node_count = int(row['node_count'])
        self.orphan_node_count = int(row['orphan_node_count'])

        # Rendering
        self.fps = float(row['fps'])
        self.draw_calls = int(row['draw_calls'])
        self.primitives_in_frame = int(row['primitives_in_frame'])
        self.objects_in_frame = int(row['objects_in_frame'])

        # Resource analysis
        self.total_meshes = int(row['total_meshes'])
        self.total_materials = int(row['total_materials'])
        self.mesh_rid_count = int(row['mesh_rid_count'])
        self.material_rid_count = int(row['material_rid_count'])
        self.mesh_hash_count = int(row['mesh_hash_count'])
        self.potential_dedup_count = int(row['potential_dedup_count'])
        self.mesh_savings_percent = float(row['mesh_savings_percent'])

        # Mobile metrics (optional)
        self.mobile_memory_usage_mb = self._parse_optional_int(row['mobile_memory_usage_mb'])
        self.mobile_temperature_celsius = self._parse_optional_float(row['mobile_temperature_celsius'])
        self.mobile_battery_percent = self._parse_optional_int(row['mobile_battery_percent'])

    @staticmethod
    def _parse_optional_int(value: str) -> Optional[int]:
        return int(value) if value.strip() else None

    @staticmethod
    def _parse_optional_float(value: str) -> Optional[float]:
        return float(value) if value.strip() else None


def format_individual_report(metrics: BenchmarkMetrics) -> str:
    """Format individual test report."""
    report = []

    report.append(f"# Benchmark Report: {metrics.test_name}\n")
    report.append(f"**Timestamp**: {metrics.timestamp}\n")
    report.append(f"**Location**: {metrics.location}\n")
    if metrics.realm:
        report.append(f"**Realm**: {metrics.realm}\n")

    report.append("\n---\n")

    # Memory Metrics
    report.append("\n## Memory Metrics\n")
    report.append("\n| Metric | Value |\n")
    report.append("|--------|-------|\n")
    report.append(f"| **Process Memory Usage (RSS)** | **{metrics.process_memory_usage_mb:.2f} MiB ({metrics.process_memory_usage_mb / 1024.0:.2f} GiB)** |\n")
    report.append(f"| Godot Static Memory | {metrics.godot_static_memory_mb:.2f} MiB |\n")
    report.append(f"| Godot Peak Memory | {metrics.godot_static_memory_peak_mb:.2f} MiB |\n")
    report.append(f"| GPU Video RAM | {metrics.gpu_video_ram_mb:.2f} MiB |\n")
    report.append(f"| GPU Texture Memory | {metrics.gpu_texture_memory_mb:.2f} MiB |\n")
    report.append(f"| GPU Buffer Memory | {metrics.gpu_buffer_memory_mb:.2f} MiB |\n")
    report.append(f"| Rust Heap Usage | {metrics.rust_heap_usage_mb:.2f} MiB |\n")
    report.append(f"| Rust Total Allocated | {metrics.rust_total_allocated_mb:.2f} MiB |\n")
    if metrics.deno_scene_count > 0:
        report.append(f"| Deno/V8 Total Memory | {metrics.deno_total_memory_mb:.2f} MiB |\n")
        report.append(f"| Deno Active Scenes | {metrics.deno_scene_count} |\n")
        report.append(f"| Deno Avg per Scene | {metrics.deno_average_memory_mb:.2f} MiB |\n")
    report.append("\n")

    # Object Counts
    report.append("## Object Counts\n")
    report.append("\n| Metric | Count |\n")
    report.append("|--------|-------|\n")
    report.append(f"| Total Objects | {metrics.total_objects} |\n")
    report.append(f"| Resources | {metrics.resource_count} |\n")
    report.append(f"| Nodes | {metrics.node_count} |\n")
    report.append(f"| Orphan Nodes | {metrics.orphan_node_count} |\n")
    report.append("\n")

    # Rendering
    report.append("## Rendering Metrics\n")
    report.append("\n| Metric | Value |\n")
    report.append("|--------|-------|\n")
    report.append(f"| FPS | {metrics.fps:.1f} |\n")
    report.append(f"| Draw Calls per Frame | {metrics.draw_calls} |\n")
    report.append(f"| Primitives per Frame | {metrics.primitives_in_frame} |\n")
    report.append(f"| Objects per Frame | {metrics.objects_in_frame} |\n")
    report.append("\n")

    # Resource Analysis
    if metrics.total_meshes > 0:
        report.append("## Resource Analysis\n")
        report.append("\n| Metric | Value |\n")
        report.append("|--------|-------|\n")
        report.append(f"| Total Mesh References | {metrics.total_meshes} |\n")
        report.append(f"| Total Material References | {metrics.total_materials} |\n")
        report.append(f"| Unique Mesh RIDs | {metrics.mesh_rid_count} |\n")
        report.append(f"| Unique Material RIDs | {metrics.material_rid_count} |\n")
        report.append(f"| Hashed Mesh Count | {metrics.mesh_hash_count} |\n")
        report.append(f"| Potential Deduplication | {metrics.potential_dedup_count} ({metrics.mesh_savings_percent:.1f}% savings) |\n")
        report.append("\n")

    # Mobile Metrics
    if metrics.mobile_memory_usage_mb is not None:
        report.append("## Mobile Metrics\n")
        report.append("\n| Metric | Value |\n")
        report.append("|--------|-------|\n")
        if metrics.mobile_memory_usage_mb is not None:
            report.append(f"| Memory Usage | {metrics.mobile_memory_usage_mb} MiB |\n")
        if metrics.mobile_temperature_celsius is not None:
            report.append(f"| Temperature | {metrics.mobile_temperature_celsius:.1f}°C |\n")
        if metrics.mobile_battery_percent is not None:
            report.append(f"| Battery | {metrics.mobile_battery_percent}% |\n")
        report.append("\n")

    return ''.join(report)


def format_consolidated_report(metrics_list: List[BenchmarkMetrics]) -> str:
    """Format consolidated report with all tests."""
    report = []

    report.append("# Decentraland Godot Explorer - Benchmark Report\n")
    report.append(f"\n**Generated**: {datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\n")
    report.append(f"\n**Total Tests**: {len(metrics_list)}\n")

    report.append("\n---\n")

    # Table of Contents
    report.append("\n## Table of Contents\n")
    for i, metrics in enumerate(metrics_list, 1):
        anchor = metrics.test_name.lower().replace(' ', '-').replace('_', '-')
        report.append(f"\n{i}. [{metrics.test_name}](#test-{i}-{anchor})")
    report.append("\n\n---\n")

    # Summary Overview
    report.append("\n## Summary Overview\n")

    # Memory Metrics
    report.append("\n### Memory Metrics\n")
    report.append("\n| Test | Process RSS (MiB) | Godot Static (MiB) | GPU VRAM (MiB) | Rust Heap (MiB) | Deno Total (MiB) |\n")
    report.append("|------|-------------------|-------------------|----------------|-----------------|------------------|\n")
    for metrics in metrics_list:
        report.append(f"| {metrics.test_name} | {metrics.process_memory_usage_mb:.2f} | {metrics.godot_static_memory_mb:.2f} | {metrics.gpu_video_ram_mb:.2f} | {metrics.rust_heap_usage_mb:.2f} | {metrics.deno_total_memory_mb:.2f} |\n")
    report.append("\n")

    # Objects Summary
    report.append("### Object Counts\n")
    report.append("\n| Test | Total Objects | Nodes | Resources | Orphan Nodes |\n")
    report.append("|------|---------------|-------|-----------|---------------|\n")
    for metrics in metrics_list:
        report.append(f"| {metrics.test_name} | {metrics.total_objects} | {metrics.node_count} | {metrics.resource_count} | {metrics.orphan_node_count} |\n")
    report.append("\n")

    # Rendering Summary
    report.append("### Rendering Metrics\n")
    report.append("\n| Test | FPS | Draw Calls | Primitives | Objects in Frame |\n")
    report.append("|------|-----|------------|------------|------------------|\n")
    for metrics in metrics_list:
        report.append(f"| {metrics.test_name} | {metrics.fps:.1f} | {metrics.draw_calls} | {metrics.primitives_in_frame} | {metrics.objects_in_frame} |\n")
    report.append("\n")

    # Resource Analysis Summary
    report.append("### Resource Analysis\n")
    report.append("\n| Test | Meshes | Materials | Mesh RIDs | Material RIDs | Dedup Potential |\n")
    report.append("|------|--------|-----------|-----------|---------------|------------------|\n")
    for metrics in metrics_list:
        report.append(f"| {metrics.test_name} | {metrics.total_meshes} | {metrics.total_materials} | {metrics.mesh_rid_count} | {metrics.material_rid_count} | {metrics.potential_dedup_count} |\n")
    report.append("\n---\n")

    # Detailed Test Results
    report.append("\n## Detailed Test Results\n")
    for i, metrics in enumerate(metrics_list, 1):
        report.append(f"\n### Test {i}: {metrics.test_name}\n")
        report.append(format_individual_report(metrics))
        report.append("\n---\n")

    return ''.join(report)


def main():
    if len(sys.argv) != 3:
        print("Usage: python convert_benchmark_csv_to_md.py <input.csv> <output.md>")
        sys.exit(1)

    input_csv = sys.argv[1]
    output_md = sys.argv[2]

    # Read CSV
    metrics_list = []
    try:
        with open(input_csv, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                metrics = BenchmarkMetrics(row)
                metrics_list.append(metrics)
    except FileNotFoundError:
        print(f"Error: File '{input_csv}' not found")
        sys.exit(1)
    except Exception as e:
        print(f"Error reading CSV: {e}")
        sys.exit(1)

    if not metrics_list:
        print("Error: No metrics found in CSV")
        sys.exit(1)

    # Generate markdown
    markdown = format_consolidated_report(metrics_list)

    # Write markdown
    try:
        with open(output_md, 'w', encoding='utf-8') as f:
            f.write(markdown)
        print(f"✓ Converted {len(metrics_list)} test(s) to Markdown: {output_md}")
    except Exception as e:
        print(f"Error writing Markdown: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
